import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Sample data with both numerical and categorical variables
data = {
    'trade_id': [1, 1, 1, 1, 2, 2, 2, 2],
    'category': ['A', 'A', 'B', 'B', 'A', 'B', 'B', 'A'],  # Categorical variable
    'price': [10, 20, 15, 1000, 300, 500, 450, 7000],  # Numerical variable with anomalies
    'volume': [100, 110, 105, 120, 150, 145, 155, 170],  # Numerical
    'volatility': [0.01, 0.02, 0.015, 0.1, 0.03, 0.04, 0.035, 0.05]  # Numerical
}
df = pd.DataFrame(data)

# Define the categorical and numerical columns
numerical_cols = ['price', 'volume', 'volatility']
categorical_cols = ['category']

# Preprocess numerical and categorical variables
# OneHotEncode categorical columns and StandardScale numerical columns
column_transformer = ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(), categorical_cols)
])

# Fit and transform the data
df_transformed = column_transformer.fit_transform(df)

# Define the autoencoder model
input_dim = df_transformed.shape[1]  # The number of features after transformation
encoding_dim = 4  # Compression to 4 dimensions (can be tuned)

input_layer = layers.Input(shape=(input_dim,))
encoded = layers.Dense(encoding_dim, activation='relu')(input_layer)
decoded = layers.Dense(input_dim, activation='linear')(encoded)

autoencoder = models.Model(inputs=input_layer, outputs=decoded)

# Compile the model
autoencoder.compile(optimizer='adam', loss='mse')

# Train the autoencoder
history = autoencoder.fit(df_transformed, df_transformed, epochs=100, batch_size=2, shuffle=True, validation_split=0.2, verbose=0)

# Use the autoencoder to predict (reconstruct) the data
df_reconstructed = autoencoder.predict(df_transformed)

# Calculate reconstruction error
reconstruction_error = np.mean(np.abs(df_transformed - df_reconstructed), axis=1)

# Set a threshold for anomaly detection (can be tuned)
threshold = np.percentile(reconstruction_error, 95)

# Flag anomalies based on reconstruction error
df['reconstruction_error'] = reconstruction_error
df['anomaly'] = df['reconstruction_error'] > threshold

# Inverse transform numerical reconstructed values back to original scale
df_reconstructed_numerical = column_transformer.named_transformers_['num'].inverse_transform(df_reconstructed[:, :len(numerical_cols)])

# Add predicted (reconstructed) numerical values to the DataFrame
df['predicted_price'] = df_reconstructed_numerical[:, 0]
df['predicted_volume'] = df_reconstructed_numerical[:, 1]
df['predicted_volatility'] = df_reconstructed_numerical[:, 2]

# Print anomalies with their predicted (reconstructed) values
anomalies = df[df['anomaly'] == True]
print(anomalies[['trade_id', 'category', 'price', 'predicted_price', 'volume', 'predicted_volume', 'volatility', 'predicted_volatility', 'reconstruction_error']])

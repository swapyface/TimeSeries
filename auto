import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Input
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Assuming your clean dataset is a Pandas DataFrame with 'category' and 'numerical_column'
df = pd.DataFrame({
    'category': ['A', 'A', 'B', 'B', 'C', 'C'],
    'numerical_column': [100, 110, 200, 195, 305, 315]
})

# Step 1: Prepare the data
# Label encode the categorical column
le = LabelEncoder()
df['category_encoded'] = le.fit_transform(df['category'])

# Standardize the numerical column
scaler = StandardScaler()
df['scaled_numerical'] = scaler.fit_transform(df[['numerical_column']])

# Step 2: Define the autoencoder model
def build_autoencoder():
    model = Sequential([
        Input(shape=(1,)),
        Dense(16, activation='relu'),
        Dense(8, activation='relu'),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')  # Output layer to reconstruct the input
    ])
    
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    
    return model

# Step 3: Train the model for each category separately
categories = df['category'].unique()

for category in categories:
    print(f"Training autoencoder for category: {category}")
    
    # Select the data for the current category
    category_data = df[df['category'] == category]['scaled_numerical'].values
    category_data = category_data.reshape(-1, 1)  # Reshape for the model
    
    # Train/test split
    X_train, X_test = train_test_split(category_data, test_size=0.2, random_state=42)
    
    # Build the autoencoder model
    model = build_autoencoder()
    
    # Train the model
    model.fit(X_train, X_train, epochs=100, batch_size=8, validation_data=(X_test, X_test), verbose=0)
    
    # Reconstruct the entire category data
    reconstruction = model.predict(category_data)
    
    # Inverse transform to get original values
    original_values = scaler.inverse_transform(category_data)
    reconstructed_values = scaler.inverse_transform(reconstruction)
    
    # Print original and reconstructed values
    print(f"Original and Reconstructed values for category '{category}':")
    for original, reconstructed in zip(original_values, reconstructed_values):
        print(f"Original: {original[0]}, Reconstructed: {reconstructed[0]}")
    
    # Step 4: Calculate and print the model score (MSE)
    mse = mean_squared_error(original_values, reconstructed_values)
    print(f"Model MSE for category '{category}': {mse}\n")